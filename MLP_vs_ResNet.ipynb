{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"DM_HW4_20161641.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"FVfzWuT22jTZ"},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from copy import deepcopy\n","import matplotlib.pyplot as plt\n","\n","#Cuda 혹은 cpu를 사용하시오.\n","############Write Your Code Here############\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n","############################################\n","\n","\n","#Custom_Dataset을 정의하시오.(10점)\n","class Custom_Dataset(Dataset):\n","    def __init__(self, X, y):\n","        #입력으로 들어온 X의 pixel값들을 0-1사이로 normalize하고 X의 shape을 (FB,C,H,W)로 변경하여 저장하여 self.X,self.y에 저장하시오.\n","        self.X = None\n","        self.y = None\n","        ############Write Your Code Here############\n","        self.X = X.reshape(-1,3,32,32) / 255.0\n","        #self.X = X / 255.0\n","        self.y = y\n","        ############################################\n","        \n","    def __len__(self):\n","        #Custom_Dataset에 저장되어있는 총 data의 개수를 result에 저장하여 반환하시오.\n","        result = 0\n","        ############Write Your Code Here############\n","        result = len(self.X)\n","        ############################################\n","        return result\n","    \n","    def __getitem__(self, idx):\n","        #self.X, self.y 에서 idx에 맞는 data를 result_X,result_y에 저장하여 반환하시오.\n","        result_X,result_y = None,None\n","        ############Write Your Code Here############\n","        result_X = self.X[idx]\n","        result_y = self.y[idx]\n","        ############################################\n","        return result_X,result_y\n","\n","    \n","#torch.nn을 사용하여 아래 함수들을 작성하시오. result는 nn.Layer중 하나이고 result를 반환함.(20점)\n","def batch_norm(dim,for_MLP=True):\n","    #for_MLP가 True일 시 MLP를 위한 BN Layer를 반환하고 False일 시 CNN을 위한 BN Layer를 반환함.\n","    ############Write Your Code Here############\n","    result = None\n","    if for_MLP == True :\n","        result = nn.BatchNorm1d(dim)\n","    else :\n","        result = nn.BatchNorm2d(dim)\n","    ############################################\n","    return result\n","\n","def fc_layer(in_dim,out_dim):\n","    #Fully Connected Layer(Dense Layer)\n","    ############Write Your Code Here############\n","    result = nn.Linear(in_dim,out_dim)\n","    ############################################\n","    return result\n","\n","def conv_layer(in_ch,out_ch,kernel_size, stride=1, padding=0):\n","    #Convolutional Layer for image\n","    ############Write Your Code Here############\n","    result = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding)\n","    ############################################\n","    return result\n","\n","def relu():\n","    #ReLU function\n","    ############Write Your Code Here############\n","    result = nn.ReLU()\n","    ############################################\n","    return result\n","\n","def flatten():\n","    #Flatten the data\n","    ############Write Your Code Here############\n","    result = nn.Flatten()\n","    ############################################\n","    return result\n","\n","\n","#skip_connection(bn -> relu -> conv -> bn -> relu -> conv)를 따르는 Res_block을 만드시오.\n","#change_res가 True인 res_block을 통과한 feature map은 resolution이 2배 작아지고 channel의 깊이는 2배로 증가함. ex) 32*8*8 -> 64*4*4\n","#위의 경우에는 skip_connection의 dimension은 1*1 conv로 맞춰줌.\n","#change_res가 False인 Res_block을 통과한 feature map은 resolution과 channel의 깊이는 그대로 유지됨. ex) 32*4*4 -> 32*4*4(20점)\n","class Res_block(nn.Module):\n","    def __init__(self, input_channel, change_res):\n","        super(Res_block,self).__init__()\n","        self.change_res = change_res\n","        if change_res:\n","            ############Write Your Code Here############\n","            self.residual_block = nn.Sequential(\n","                conv_layer(input_channel,input_channel*2,(3,3), stride=2, padding=1),\n","                batch_norm(input_channel*2,for_MLP=False),\n","                relu(),\n","                conv_layer(input_channel*2,input_channel*2,(3,3), stride=1, padding=1),\n","                batch_norm(input_channel*2,for_MLP=False)\n","            )\n","            ############################################\n","        else:\n","            ############Write Your Code Here############\n","            self.residual_block = nn.Sequential(\n","                conv_layer(input_channel,input_channel,(3,3), stride=1, padding=1),\n","                batch_norm(input_channel,for_MLP=False),\n","                relu(),\n","                conv_layer(input_channel,input_channel,(3,3), stride=1, padding=1),\n","                batch_norm(input_channel,for_MLP=False)\n","            )\n","            ############################################\n","        ############Write Your Code Here############\n","        self.relu = relu()\n","        self.short_cut = nn.Sequential(\n","            conv_layer(input_channel,input_channel*2,(1,1), stride=2),\n","            batch_norm(input_channel*2,for_MLP=False)\n","        )\n","        ############################################\n","    def forward(self,X):\n","        ############Write Your Code Here############\n","        if self.change_res :\n","            X = self.short_cut(X) + self.residual_block(X)\n","        else :\n","            X = X + self.residual_block(X)\n","        X = self.relu(X)\n","        ############################################\n","        return X\n","\n","    \n","#Skip Connection을 이용하여 20개 이상의 layer를 가지고 테스트 셋에대하여 50% 이상의 성능을 주는 MLP를 만드시오.\n","#nn.ModuleList를 사용하면 많을 층의 layer를 쌓는데 용이함.(20점)\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(MLP,self).__init__()\n","        ############Write Your Code Here############\n","        self.flatten = nn.Flatten(start_dim=1)\n","        self.layers1 = nn.ModuleList()\n","        for i in range(3) :\n","            self.layers1.append(nn.Sequential(\n","                fc_layer(input_dim,input_dim),\n","                relu(),\n","                fc_layer(input_dim,input_dim),\n","                relu()\n","            ))\n","        \n","        self.hidden_dim1 = max(input_dim//2,output_dim)\n","        self.hidden_layer1 = nn.Sequential(\n","            fc_layer(input_dim,self.hidden_dim1),\n","            relu()\n","        )\n","        self.layers2 = nn.ModuleList()\n","        for i in range(3,6) :\n","            self.layers2.append(nn.Sequential(\n","                fc_layer(self.hidden_dim1,self.hidden_dim1),\n","                relu(),\n","                fc_layer(self.hidden_dim1,self.hidden_dim1),\n","                relu()\n","            ))\n","        \n","        self.hidden_dim2 = max(self.hidden_dim1//2,output_dim)\n","        self.hidden_layer2 = nn.Sequential(\n","            fc_layer(self.hidden_dim1,self.hidden_dim2),\n","            relu()\n","        )\n","        self.layers3 = nn.ModuleList()\n","        for i in range(6,9) :\n","            self.layers3.append(nn.Sequential(\n","                fc_layer(self.hidden_dim2,self.hidden_dim2),\n","                relu(),\n","                fc_layer(self.hidden_dim2,self.hidden_dim2),\n","                relu()\n","            ))\n","\n","        self.output_layer = nn.Sequential(\n","            fc_layer(self.hidden_dim2,output_dim),\n","            nn.Softmax(dim = 1)\n","        )\n","        self.relu = relu()\n","        ############################################\n","    def forward(self,X):\n","        ############Write Your Code Here############\n","        X = self.flatten(X)\n","        for layer in self.layers1 :\n","            X = X + layer(X)\n","            X = self.relu(X)\n","        X = self.hidden_layer1(X)\n","        for layer in self.layers2 :\n","            X = X + layer(X)\n","            X = self.relu(X)\n","        X = self.hidden_layer2(X)\n","        for layer in self.layers3 :\n","            X = X + layer(X)\n","            X = self.relu(X)\n","        X = self.output_layer(X)\n","        ############################################\n","        return X\n","        \n","#Res_Block을 사용하여 테스트 셋에대한 70% 이상의 성능을 주는 CNN 모델을 만드시오.\n","#flatten전에 nn.AdaptiveAvgPool2d를 사용하면 dimension맞추기가 쉬움.(20점)\n","class CNN(nn.Module):\n","    def __init__(self, input_channel, class_number, block_number):\n","        super(CNN,self).__init__()\n","        ############Write Your Code Here############\n","        self.in_planes = 64\n","        self.conv1 = conv_layer(3, 64, 3, 1, 1)\n","        self.bn1 = batch_norm(64,for_MLP=False)\n","\n","        def make_RES_layer(planes, block_number, stride):\n","            strides = [stride] + [1]*(block_number-1)\n","            layers = []\n","            for stride in strides:\n","                if stride == 1 :\n","                    layers.append(Res_block(self.in_planes, change_res = False))\n","                else :\n","                    layers.append(Res_block(self.in_planes, change_res = True))\n","                    self.in_planes = planes * 2\n","            return nn.Sequential(*layers)\n","\n","        self.layer1 = make_RES_layer(64,block_number[0],stride = 2)\n","        self.layer2 = make_RES_layer(128,block_number[1],stride = 2)\n","        self.layer3 = make_RES_layer(256,block_number[2],stride = 2)\n","        self.layer4 = make_RES_layer(512,block_number[3],stride = 2)\n","        self.linear = fc_layer(512 *2,class_number)\n","\n","\n","        self.relu = relu()\n","        ############################################\n","    def forward(self,X):\n","        ############Write Your Code Here############\n","        X = self.conv1(X)\n","        X = self.bn1(X)\n","        X = self.relu(X)\n","        X = self.layer1(X)\n","        X = self.layer2(X)\n","        X = self.layer3(X)\n","        X = self.layer4(X)\n","        X = nn.functional.avg_pool2d(X,2)\n","        X = X.view(X.size(0),-1)\n","        X = self.linear(X)\n","        ############################################\n","        return X\n","\n","#loader에 있는 모든 data들에 대한 정확도를 구하여 accuracy에 저장하여 accuracy를 return하는 함수를 구현하시오.(10점)\n","def evaluate(model, loader):\n","    model.eval()\n","    accuracy = 0\n","    total_example = 0\n","    correct_example = 0\n","    for data in loader:\n","        x,y = data\n","        x = torch.tensor(x, device = device)\n","        y = torch.tensor(y, device = device)\n","        ############Write Your Code Here############\n","        outputs = model(x.float())\n","        _, predict = torch.max(outputs.data,1)\n","        total_example += y.size(0)\n","        correct_example += (predict == y).sum().item()\n","        ############################################\n","    ############Write Your Code Here############\n","    accuracy = 100 * correct_example / total_example\n","    ############################################\n","    model.train()\n","    return accuracy\n","\n","#epoch마다 train_loader에 있는 batch들을 사용하여 모델을 학습하고\n","#epoch의 마지막 iteration에서는 모델의 validation accuracy를 확인하여 제일 높은 val. acc.를 가진 model을 best_model에 저장하고\n","#val_acc에는 매 epoch마다 구해진 validation accuracy를 저장하시오.\n","#running_loss에는 각각의 epoch에서 모든 batch의 loss를 다 더하여 저장하시오.\n","#모든 epoch의 validation accuracy를 val_acc에 저장하여 best_model과 val_acc를 return하는 함수를 구현하시오.(10점)\n","def train(model, epoches, train_loader, val_loader, optimizer, criteria):\n","    best_score = 0\n","    best_model = None\n","    batch_len = len(train_loader)\n","    val_acc = []\n","    for epoch in range(epoches):\n","        running_loss = 0\n","        for i,data in enumerate(train_loader):\n","            x,y = data\n","            x = torch.tensor(x, device = device)\n","            y = torch.tensor(y, device = device)\n","            ############Write Your Code Here############\n","            optimizer.zero_grad()\n","            outputs = model(x.float())\n","            loss = criteria(outputs,y)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            ############################################\n","            \n","            #epoch의 마지막 iteration\n","            if i % batch_len == batch_len-1:\n","                print(f'{epoch+1}th iteration loss :',running_loss/batch_len)\n","                running_loss = 0\n","                ############Write Your Code Here############\n","                score = evaluate(model,val_loader)\n","                print(f'{epoch+1}th validation accuracy :',score)\n","                val_acc.append(score)\n","                if score > best_score :\n","                    best_score = score\n","                    best_model = deepcopy(model)\n","                ############################################\n","    return best_model, val_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"DeY3e2y_2jTd","outputId":"8c20e946-7ce6-4ae6-ab5d-c56babfa000f"},"source":["#(50점)\n","#Read the data\n","trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True)\n","testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True)\n","\n","X_train, Y_train = trainset.data, np.array(trainset.targets)\n","X_test, Y_test = testset.data, np.array(testset.targets)\n","\n","\n","#앞서 정의한 Custom_Dataset과 DataLoader를 사용하여 train_loader,val_loader,test_loader를 정의하시오.\n","#Batch_size는 본인의 컴퓨터 사향에 맞게 변경하면 됨. Validation Set으로 Train Set의 20%를 사용함.\n","#Preprocessing\n","train_loader = None\n","val_loader = None\n","test_loader = None\n","batch_size = 1\n","############Write Your Code Here############\n","from torch.utils.data.dataset import random_split\n","batch_size = 32\n","dataset = Custom_Dataset(X_train,Y_train)\n","train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","trainset, valset = random_split(dataset,[train_size,test_size])\n","train_loader = DataLoader(dataset = trainset, batch_size = batch_size)\n","val_loader = DataLoader(dataset = valset, batch_size = batch_size)\n","\n","dataset2 = Custom_Dataset(X_test,Y_test)\n","test_loader = DataLoader(dataset = dataset2, batch_size = batch_size)\n","############################################\n","\n","\n","#앞서 정의한 MLP,CNN을 사용하여 mlp_model,cnn_model을 정의하시오.\n","#Define the model\n","mlp_model = None\n","cnn_model = None\n","############Write Your Code Here############\n","import torch.nn.init as init\n","def _weights_init(net): # Weight 초기화 함수\n","    for m in net.modules():\n","        if isinstance(m, nn.Conv2d):\n","            init.kaiming_normal(m.weight, mode='fan_out')\n","        elif isinstance(m, nn.BatchNorm2d):\n","            init.constant(m.weight, 1)\n","            init.constant(m.bias, 0)\n","        elif isinstance(m, nn.Linear):\n","            init.normal(m.weight, std=1e-3)\n","\n","mlp_model = MLP(32*32*3,10).float()\n","mlp_model.apply(_weights_init)\n","cnn_model = CNN(3,10,[2,2,2,2]).float()\n","cnn_model.apply(_weights_init)\n","############################################\n","mlp_model.to(device)\n","cnn_model.to(device)\n","\n","\n","#앞서 정의한 train함수를 사용하여 best_mlp, mpl_val_acc, best_cnn, cnn_val_acc를 구하시오.\n","#Train the model\n","best_mlp = None\n","mlp_val_acc = None\n","best_cnn = None\n","cnn_val_acc = None\n","############Write Your Code Here############\n","\n","# 학습 진행중 끊기는 일이 잦아 (교수님께서 가능하다고 답변을 주셔서) model save, load를 구현하였습니다. \n","# 용량 관계로 checkpoint model은 따로 첨부하지 않았습니다.\n","# 만약 체점에 필요하시다면 Google Drive를 통해 공유하도록 하겠습니다!\n","\n","import torch.optim as optim\n","import os\n","\n","\n","mlp_checkpoint = True # Checkpoint Load\n","start_epoch = 0\n","best_acc = 0\n","mlp_val_acc = []\n","criteria = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(mlp_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=0.001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor = 0.5, patience = 0, verbose = True)\n","\n","if mlp_checkpoint :\n","    checkpoint = torch.load('./checkpoint/mlp_checkpoint.pth')\n","    mlp_model.load_state_dict(checkpoint['model'])\n","    best_acc = checkpoint['best_acc']\n","    mlp_val_acc = checkpoint['val_acc']\n","    start_epoch = checkpoint['epoch']\n","    best_mlp = mlp_model\n","\n","\n","\n","mlp_model.to(device)\n","\n","for epoch in range(start_epoch,130,5) : # 학습이 더 진행되지 않도록 일부러 range를 종료 시점의 epoch로 변경해 놓았습니다\n","    print(f\"<< Epoch :: {epoch} >>\")\n","    best_mlp, temp_val_acc = train(mlp_model, 5, train_loader, val_loader, optimizer, criteria)\n","    mlp_val_acc.append(temp_val_acc)\n","    mlp_acc = evaluate(best_mlp,val_loader)\n","    print(f'{epoch} MLP accuracy:',mlp_acc)\n","    \n","    if mlp_acc > best_acc: # Checkpoint Save\n","        print('Saving..')\n","        state = {\n","            'model': best_mlp.state_dict(),\n","            'best_acc': best_acc,\n","            'val_acc': mlp_val_acc,\n","            'epoch': epoch+5,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/mlp_checkpoint.pth')\n","        best_acc = mlp_acc\n","\n","    scheduler.step(mlp_acc)\n","    print(\"last lr : \", scheduler._last_lr)\n","    print(\"optimizer lr : \", optimizer.param_groups[0]['lr'])\n","\n","\n","\n","\n","\n","\n","\n","cnn_checkpoint = True # Checkpoint Load\n","start_epoch = 0\n","best_acc = 0\n","cnn_val_acc = []\n","criteria = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=0.001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor = 0.5, patience = 3, verbose = True)\n","\n","if cnn_checkpoint :\n","    checkpoint = torch.load('./checkpoint/cnn_checkpoint.pth')\n","    cnn_model.load_state_dict(checkpoint['model'])\n","    best_acc = checkpoint['best_acc']\n","    cnn_val_acc = checkpoint['val_acc']\n","    start_epoch = checkpoint['epoch']\n","    best_cnn = cnn_model\n","\n","\n","cnn_model.to(device)\n","for epoch in range(start_epoch,215,5) : # 학습이 더 진행되지 않도록 일부러 range를 종료 시점의 epoch로 변경해 놓았습니다\n","    print(f\"<< Epoch :: {epoch} >>\")\n","    best_cnn, temp_val_acc = train(cnn_model, 5, train_loader, val_loader, optimizer, criteria)\n","    cnn_val_acc.append(temp_val_acc)\n","    cnn_acc = evaluate(best_cnn,val_loader)\n","    print(f'{epoch} CNN accuracy:',cnn_acc)\n","    \n","    if cnn_acc > best_acc: # Checkpoint Save\n","        print('Saving..')\n","        state = {\n","            'model': best_cnn.state_dict(),\n","            'best_acc': best_acc,\n","            'val_acc': cnn_val_acc,\n","            'epoch': epoch+5,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/cnn_checkpoint.pth')\n","        best_acc = cnn_acc\n","\n","    scheduler.step(cnn_acc)\n","    print(\"last lr : \", scheduler._last_lr)\n","    print(\"optimizer lr : \", optimizer.param_groups[0]['lr'])\n","\n","############################################\n","\n","\n","#앞서 정의한 evaluate함수와 best_model들을 사용하여 mlp_acc, cnn_acc를 구하시오.\n","#Test Accuracy\n","mlp_acc = None  \n","cnn_acc = None \n","############Write Your Code Here############\n","mlp_acc = evaluate(best_mlp,test_loader)\n","cnn_acc = evaluate(best_cnn,test_loader)\n","############################################\n","print('MLP accuracy:',mlp_acc)\n","print('CNN accuracy:',cnn_acc)\n","\n","\n","#앞서 구한 val_acc들을 사용하여 이해 가능한 그래프를 그리시오.\n","#Validation Accuracy Plot\n","############Write Your Code Here############\n","plt.plot(sum(mlp_val_acc, []), marker='o', label = \"MLP\")\n","plt.plot(sum(cnn_val_acc, []), marker='o', label = \"CNN\")\n","plt.legend()\n","plt.xlabel('epoch')\n","plt.ylabel('validation accuracy')\n","plt.show()\n","############################################"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["MLP accuracy: 50.49\n","CNN accuracy: 83.13\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"3Be6yiJ2EzUs"},"source":[""],"execution_count":null,"outputs":[]}]}